{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gOPVrh1gIxx"
      },
      "source": [
        "# Machine Learning Lab 2\n",
        "\n",
        "## Assignment 3 (Deadline : 05/02/2023 11:59PM)\n",
        "\n",
        "Total Points : 25\n",
        "\n",
        "Your answers must be entered in LMS by midnight of the day it is due. \n",
        "\n",
        "If the question requires a textual response, you can create a PDF and upload that. \n",
        "\n",
        "The PDF might be generated from MS-WORD, LATEX, the image of a hand- written response, or using any other mechanism. \n",
        "\n",
        "Code must be uploaded and may require demonstration to the TA. \n",
        "\n",
        "Numbers in the parentheses indicate points allocated to the question. \n",
        "\n",
        "**Naming Convention**: FirstName_LastName_Lab3_TLP23.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7C5soefgYNt"
      },
      "source": [
        "**Assignment**: 3-class Sentiment Analysis with LSTM on Twitter Data\n",
        " \n",
        "\n",
        "**Objective**:\n",
        "The objective of this assignment is to train a LSTM neural network to perform 3-class sentiment analysis on Twitter data.\n",
        " \n",
        "\n",
        "**Dataset**:\n",
        "The dataset used in this assignment is the Sentiment140 dataset, which can be downloaded from http://help.sentiment140.com/for-students. The dataset consists of 1.6 million tweets, labeled as positive (4), neutral (2), or negative (0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lap-6Niagm5n"
      },
      "source": [
        "\n",
        "*   Collect a sample of at least 100,000 tweets from the dataset **(1 points)**\n",
        "\n",
        "\n",
        "*   Preprocess the text data by removing punctuation, lowercasing, removing stop words, and tokenizing the words **(3 points)**\n",
        "\n",
        "*   Split the data into training and testing sets, and pad the sequences to the same length **(2 points)**\n",
        "\n",
        "*   Build a LSTM model to classify the tweets as positive, neutral, or negative. The model should have an Embedding layer, followed LSTM layers of your choosing, and a dense layer for output **(7 points)**\n",
        "\n",
        "*   Train the model on the training data and evaluate its performance on the testing data **(3 points)**\n",
        "\n",
        "\n",
        "*   Fine-tune the model by experimenting with different architectures, optimizers, activation functions, and hyperparameters. Feel free to experiment with GRUs **(4 points)**\n",
        "\n",
        "\n",
        "*   Report the accuracy, precision, recall, and F1 score of the model on the testing data. Inclue graphs and necessary data. Include this in a markdown cell within the notebook. Compare the basic LSTM model against SOTA and other architectures which you can directly import **(3 points)**\n",
        "\n",
        "\n",
        "*   Use the trained model to predict the sentiment of 25 new tweets with positive (2), neutral (1), or negative (0) **(2 points)**\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L4xyhj02iHx3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/kishlay/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "2023-02-08 23:24:58.298309: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-08 23:24:58.479434: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-02-08 23:24:59.219674: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-08 23:24:59.219760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-02-08 23:24:59.219769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import string\n",
        "import nltk\n",
        "import torchtext\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(57103, 3)\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(columns=['sentiment', 'tweet'])\n",
        "directory = './ML2Lab2_LSTM/ML2Lab2_LSTM/'\n",
        "for fname in os.listdir(directory):\n",
        "    if '.txt' in fname:\n",
        "        df2 = pd.read_csv(directory+fname, sep='\\t', header=None, quoting=csv.QUOTE_NONE).drop([0], axis=1).rename(columns={1:'sentiment',2:'tweet'})\n",
        "    elif '.tsv' in fname:\n",
        "        df2 = pd.read_csv(directory+fname, sep='\\t', header=None, quoting=csv.QUOTE_NONE).drop([0,1], axis=1).rename(columns={2:'sentiment',3:'tweet'})\n",
        "    df = pd.concat([df,df2], axis=0)\n",
        "\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Saturday without Leeds United is like Sunday w...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Catch Rainbow Valley at the @CBC #IMAF2014 Gal...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>\"@NiklaklePinkel it doesn't really count, I wa...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>\"#BEARDOWN Wish us luck...we may need it. (@ G...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>We're so excited to be part of the Still We Ri...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                              tweet    3\n",
              "0  negative  Saturday without Leeds United is like Sunday w...  NaN\n",
              "1  positive  Catch Rainbow Valley at the @CBC #IMAF2014 Gal...  NaN\n",
              "2  positive  \"@NiklaklePinkel it doesn't really count, I wa...  NaN\n",
              "3  positive  \"#BEARDOWN Wish us luck...we may need it. (@ G...  NaN\n",
              "4  positive  We're so excited to be part of the Still We Ri...  NaN"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Saturday without Leeds United is like Sunday w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>Catch Rainbow Valley at the @CBC #IMAF2014 Gal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>\"@NiklaklePinkel it doesn't really count, I wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>\"#BEARDOWN Wish us luck...we may need it. (@ G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>We're so excited to be part of the Still We Ri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                              tweet\n",
              "0  negative  Saturday without Leeds United is like Sunday w...\n",
              "1  positive  Catch Rainbow Valley at the @CBC #IMAF2014 Gal...\n",
              "2  positive  \"@NiklaklePinkel it doesn't really count, I wa...\n",
              "3  positive  \"#BEARDOWN Wish us luck...we may need it. (@ G...\n",
              "4  positive  We're so excited to be part of the Still We Ri..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(3, axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment    1\n",
              "tweet        1\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment    0\n",
              "tweet        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(57102, 2)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        saturday without leeds united is like sunday w...\n",
              "1        catch rainbow valley at the @cbc #imaf2014 gal...\n",
              "2        \"@niklaklepinkel it doesn't really count, i wa...\n",
              "3        \"#beardown wish us luck...we may need it. (@ g...\n",
              "4        we're so excited to be part of the still we ri...\n",
              "                               ...                        \n",
              "57097    it's a wednesday girls night out as '90's band...\n",
              "57098    \"night college course sorted, just have to enr...\n",
              "57099    for the 1st time in 30 years. for your splendi...\n",
              "57100    nurses day - 12 may 2012. nursing: the heart b...\n",
              "57101    we have 15 minutes left until the 2nd episode ...\n",
              "Name: tweet, Length: 57102, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to lowercase\n",
        "df['tweet'] = df['tweet'].apply(lambda x:x.lower())\n",
        "df['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        saturday without leeds united is like sunday w...\n",
              "1        catch rainbow valley at the cbc imaf2014 gala ...\n",
              "2        niklaklepinkel it doesnt really count i was de...\n",
              "3        beardown wish us luckwe may need it  georgia d...\n",
              "4        were so excited to be part of the still we ris...\n",
              "                               ...                        \n",
              "57097    its a wednesday girls night out as 90s band wi...\n",
              "57098    night college course sorted just have to enrol...\n",
              "57099    for the 1st time in 30 years for your splendif...\n",
              "57100    nurses day  12 may 2012 nursing the heart beat...\n",
              "57101    we have 15 minutes left until the 2nd episode ...\n",
              "Name: tweet, Length: 57102, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove punctuation\n",
        "df['tweet'] = df['tweet'].apply(lambda x:x.translate(str.maketrans('', '', string.punctuation)))\n",
        "df['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        saturday without leeds united like sunday with...\n",
              "1        catch rainbow valley cbc imaf2014 gala oct 26 ...\n",
              "2        niklaklepinkel doesnt really count decorating ...\n",
              "3        beardown wish us luckwe may need georgia dome ...\n",
              "4        excited part still rise gala dec 3 join us war...\n",
              "                               ...                        \n",
              "57097    wednesday girls night 90s band wilson phillips...\n",
              "57098    night college course sorted enrole tomorrow fi...\n",
              "57099    1st time 30 years splendiferous entertainment ...\n",
              "57100     nurses day 12 may 2012 nursing heart beat health\n",
              "57101    15 minutes left 2nd episode styled rock uknavi...\n",
              "Name: tweet, Length: 57102, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove stopwords\n",
        "stop = stopwords.words('english')\n",
        "df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "df['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "token_dict = {}\n",
        "tweet_tokens = []\n",
        "stemmer = PorterStemmer()\n",
        "cur_val = 1\n",
        "max_len = 0\n",
        "\n",
        "for idx, tweet in enumerate(df['tweet']):\n",
        "    tokens = tokenizer(tweet)\n",
        "    if(max_len<len(tokens)):\n",
        "        max_len = len(tokens)\n",
        "    num_list = []\n",
        "    for word in tokens:\n",
        "        word = stemmer.stem(word)\n",
        "        if word not in token_dict:\n",
        "            token_dict[word] = cur_val\n",
        "            cur_val+=1\n",
        "        num_list.append(token_dict[word])\n",
        "    tweet_tokens.append(num_list)\n",
        "    \n",
        "df[\"tweet\"] = tweet_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(39, 75368)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len, len(token_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['tweet'] = df['tweet'].apply(lambda x:x+[0]*(max_len-len(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39    57102\n",
              "Name: tweet, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tweet'].apply(lambda x:len(x)).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 2, 6, 7, 8, 9, 10, 11, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 0, 0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[22, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>[35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>[50, 51, 52, 53, 17, 54, 55, 56, 37, 57, 58, 5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                              tweet\n",
              "0          0  [1, 2, 3, 4, 5, 6, 2, 6, 7, 8, 9, 10, 11, 0, 0...\n",
              "1          2  [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 0, 0,...\n",
              "2          2  [22, 8, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32...\n",
              "3          2  [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 4...\n",
              "4          2  [50, 51, 52, 53, 17, 54, 55, 56, 37, 57, 58, 5..."
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_map = {'positive':2, 'neutral':1, 'negative': 0}\n",
        "df['sentiment'] = df['sentiment'].apply(lambda x:sent_map[x])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = list(train.itertuples(index=False, name=None))\n",
        "test = list(val.itertuples(index=False, name=None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x = np.array([tweet[:15] for label, tweet  in train])\n",
        "train_y = np.array([label for label, tweet in train])\n",
        "val_x = np.array([tweet[:15] for label, tweet in test])\n",
        "val_y = np.array([label for label, tweet in test])\n",
        "\n",
        "max_len=15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_y, val_y = pd.get_dummies(train_y), pd.get_dummies(val_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-08 23:25:16.083058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:16.121689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:16.121978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:16.122863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-08 23:25:16.124259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:16.124544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:16.124730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:18.207092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:18.207323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:18.207471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-08 23:25:18.207612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3625 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 15, 100)           7536800   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10)                4440      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,541,273\n",
            "Trainable params: 7,541,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "embedding_vector_features = 100\n",
        "model=Sequential()\n",
        "model.add(Embedding(len(token_dict),embedding_vector_features,input_length=max_len))\n",
        "model.add(LSTM(10))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-08 23:25:21.915368: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8302\n",
            "2023-02-08 23:25:22.111790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "2023-02-08 23:25:22.114006: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x60f2a8f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-02-08 23:25:22.114044: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
            "2023-02-08 23:25:22.122628: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-02-08 23:25:22.215856: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-02-08 23:25:22.267284: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1428/1428 [==============================] - 31s 19ms/step - loss: 0.8306 - accuracy: 0.6074 - val_loss: 0.7381 - val_accuracy: 0.6723\n",
            "Epoch 2/10\n",
            "1428/1428 [==============================] - 10s 7ms/step - loss: 0.5346 - accuracy: 0.7852 - val_loss: 0.7759 - val_accuracy: 0.6673\n",
            "Epoch 3/10\n",
            "1428/1428 [==============================] - 10s 7ms/step - loss: 0.3092 - accuracy: 0.8841 - val_loss: 0.8917 - val_accuracy: 0.6611\n",
            "Epoch 4/10\n",
            "1428/1428 [==============================] - 10s 7ms/step - loss: 0.1853 - accuracy: 0.9344 - val_loss: 1.0563 - val_accuracy: 0.6547\n",
            "Epoch 5/10\n",
            "1428/1428 [==============================] - 9s 7ms/step - loss: 0.1204 - accuracy: 0.9570 - val_loss: 1.2687 - val_accuracy: 0.6440\n",
            "Epoch 6/10\n",
            "1428/1428 [==============================] - 10s 7ms/step - loss: 0.0810 - accuracy: 0.9714 - val_loss: 1.4686 - val_accuracy: 0.6400\n",
            "Epoch 7/10\n",
            "1428/1428 [==============================] - 9s 7ms/step - loss: 0.0577 - accuracy: 0.9786 - val_loss: 1.6285 - val_accuracy: 0.6295\n",
            "Epoch 8/10\n",
            "1428/1428 [==============================] - 9s 6ms/step - loss: 0.0438 - accuracy: 0.9844 - val_loss: 1.8283 - val_accuracy: 0.6245\n",
            "Epoch 9/10\n",
            "1428/1428 [==============================] - 9s 6ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 1.9867 - val_accuracy: 0.6222\n",
            "Epoch 10/10\n",
            "1428/1428 [==============================] - 9s 6ms/step - loss: 0.0279 - accuracy: 0.9894 - val_loss: 2.0951 - val_accuracy: 0.6242\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f18b3796d60>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_x,train_y,validation_data=(val_x,val_y),epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('./ML2Lab2_LSTM/ML2Lab2_LSTM/testdata.manual.2009.06.14.csv',names = ['sentiment','col2','col3','col4','col5','tweet'])\n",
        "X_test = test_df['tweet']\n",
        "y_test = test_df['sentiment']\n",
        "y_test = y_test//2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_df = test_df['tweet'] = test_df['tweet'].apply(lambda x:x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# stop = stopwords.words('english')\n",
        "# test_df['tweet'] = test_df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "# tweet_tokens = []\n",
        "\n",
        "# for idx, tweet in enumerate(test_df['tweet']):\n",
        "#     tokens = tokenizer(tweet)\n",
        "#     num_list = []\n",
        "#     for word in tokens:\n",
        "#         word = stemmer.stem(word)\n",
        "#         if word not in token_dict:\n",
        "#             token_dict[word] = cur_val\n",
        "\n",
        "#         num_list.append(token_dict[word])\n",
        "#     num_list = num_list[:15]\n",
        "#     tweet_tokens.append(num_list)\n",
        "\n",
        "# y_fin = model.predict(np.asarray(tweet_tokens))\n",
        "# y_fin"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/home/kishlay/PythonVENVs/PytorchCUDA/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "classifier = pipeline(\"text-classification\", model=\"j-hartmann/sentiment-roberta-large-english-3-classes\", return_all_scores=True)\n",
        "\n",
        "test_df = pd.read_csv('./ML2Lab2_LSTM/ML2Lab2_LSTM/testdata.manual.2009.06.14.csv',names = ['sentiment','col2','col3','col4','col5','tweet'])\n",
        "X_test = test_df['tweet']\n",
        "y_test = test_df['sentiment']\n",
        "y_test = y_test//2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.82      0.85       177\n",
            "           1       0.68      0.94      0.79       139\n",
            "           2       0.92      0.73      0.81       182\n",
            "\n",
            "    accuracy                           0.82       498\n",
            "   macro avg       0.83      0.83      0.82       498\n",
            "weighted avg       0.84      0.82      0.82       498\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = []\n",
        "for i in range(len(list(X_test))):\n",
        "  y_pred.append(np.argmax(pd.DataFrame(classifier(X_test[i])[0])['score']))\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PytorchCUDA",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "8a89a7902cc404c6ab067fe029b7c871ddc77cc2c82eb448ce6c187577671387"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
